{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a36abc9-47b6-4e9a-8d2c-330e64012db2",
   "metadata": {},
   "source": [
    "# 迁移学习微调训练图像分类模型\n",
    "\n",
    "在自己的图像分类数据集上，使用ImageNet预训练图像分类模型初始化，改动分类层，迁移学习微调训练\n",
    "\n",
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "[代码运行云GPU环境](https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1)：GPU RTX 3060、CUDA v11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c174f-33c0-44fa-af53-14237d35b37d",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6b35d923-b9e9-4ea4-914a-5bf05b93a2b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:31:45.178953300Z",
     "start_time": "2024-04-09T08:31:45.063954500Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 获取计算硬件\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9499c1-0594-48b8-80f0-e7fdbc30dbe3",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "81f0ca03-de86-450d-a47e-6f0e7c19d97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:31:46.605244700Z",
     "start_time": "2024-04-09T08:31:46.466187700Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d059c79-5b67-49fe-9baa-1bcd363208dc",
   "metadata": {},
   "source": [
    "## 载入图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5fd21e05-6cd0-4e06-a0f1-a029a79ddf86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:20.619898800Z",
     "start_time": "2024-04-09T08:32:20.562138300Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_dir = r'D:\\dataset\\sr'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dcf6544a-6af5-4b07-93df-d863157b9290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:45.652457700Z",
     "start_time": "2024-04-09T08:32:45.452805800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集路径 D:\\dataset\\sr\\train\n",
      "测试集路径 D:\\dataset\\sr\\val\n",
      "训练集图像数量 22046\n",
      "类别个数 2\n",
      "各类别名称 ['parasitized', 'uninfected']\n",
      "测试集图像数量 5512\n",
      "类别个数 2\n",
      "各类别名称 ['parasitized', 'uninfected']\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('训练集路径', train_path)\n",
    "print('测试集路径', test_path)\n",
    "\n",
    "from torchvision import datasets\n",
    "# 载入训练集\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "# 载入测试集\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
    "\n",
    "print('训练集图像数量', len(train_dataset))\n",
    "print('类别个数', len(train_dataset.classes))\n",
    "print('各类别名称', train_dataset.classes)\n",
    "print('测试集图像数量', len(test_dataset))\n",
    "print('类别个数', len(test_dataset.classes))\n",
    "print('各类别名称', test_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e98be-4648-4d34-9e6c-273a55127b4d",
   "metadata": {},
   "source": [
    "## 类别和索引号 映射字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0f737200-3afd-46f7-9c42-52c66829572e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:51.815674900Z",
     "start_time": "2024-04-09T08:32:51.729809200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各类别名称\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)\n",
    "# 映射关系：类别 到 索引号\n",
    "train_dataset.class_to_idx\n",
    "# 映射关系：索引号 到 类别\n",
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0baa451-a3c8-456a-a1ad-ea814dc9958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:52.960295700Z",
     "start_time": "2024-04-09T08:32:52.903448Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'parasitized', 1: 'uninfected'}"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eec89734-ec52-430c-a756-55faa2ce549b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:54.538375100Z",
     "start_time": "2024-04-09T08:32:54.393347900Z"
    }
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device: 'idx_to_labels.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 保存为本地的 npy 文件\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43midx_to_labels.npy\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43midx_to_labels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      3\u001B[0m np\u001B[38;5;241m.\u001B[39msave(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlabels_to_idx.npy\u001B[39m\u001B[38;5;124m'\u001B[39m, train_dataset\u001B[38;5;241m.\u001B[39mclass_to_idx)\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\numpy\\lib\\npyio.py:542\u001B[0m, in \u001B[0;36msave\u001B[1;34m(file, arr, allow_pickle, fix_imports)\u001B[0m\n\u001B[0;32m    540\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m file\u001B[38;5;241m.\u001B[39mendswith(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    541\u001B[0m         file \u001B[38;5;241m=\u001B[39m file \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m.npy\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m--> 542\u001B[0m     file_ctx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mwb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    544\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m file_ctx \u001B[38;5;28;01mas\u001B[39;00m fid:\n\u001B[0;32m    545\u001B[0m     arr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masanyarray(arr)\n",
      "\u001B[1;31mOSError\u001B[0m: [Errno 28] No space left on device: 'idx_to_labels.npy'"
     ]
    }
   ],
   "source": [
    "# 保存为本地的 npy 文件\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d3824-e6bb-4f50-9802-f073d9151311",
   "metadata": {},
   "source": [
    "## 定义数据加载器DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a787702d-61c6-41af-9cbd-19bc5d3baae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:55.823629100Z",
     "start_time": "2024-04-09T08:32:55.756667800Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 训练集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# 测试集的数据加载器\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52d04-a791-4feb-8b57-af98b253ebba",
   "metadata": {},
   "source": [
    "## 导入训练需使用的工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "684da643-5a88-4ba2-b49c-5dc98b35100e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:32:59.310568100Z",
     "start_time": "2024-04-09T08:32:59.253486700Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b9c90-160f-451f-a46b-6e846424cc0a",
   "metadata": {},
   "source": [
    "## 选择迁移学习训练方式\n",
    "\n",
    "斯坦福CS231N【迁移学习】中文精讲：https://www.bilibili.com/video/BV1K7411W7So\n",
    "\n",
    "斯坦福CS231N【迁移学习】官方笔记：https://cs231n.github.io/transfer-learning\n",
    "\n",
    "如果你的数据集和MS COCO数据集的图像域**类似**（街景、动植物、生活用品），可以保留预训练模型权重，在自己的数据集上迁移学习微调分类输出层或所有层。站在巨人的肩膀上，复用预训练模型在MS COCO数据集上学习到的图像特征。（Transfer Learning, Fine Tuning）\n",
    "\n",
    "如果你的数据集和MS COCO数据集的图像域**不类似**（医疗影像、显微镜图像、工业检测、天文照片、动画、油画），可以随机初始化模型权重，在自己的数据集上重新训练所有层。（From Scratch）。或者冻结底层权重，只重新训练顶层，复用预训练模型在MS COCO数据集上学习到的底层图像特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146006e-6bb2-4b34-8530-6c762398938e",
   "metadata": {},
   "source": [
    "### 选择一：只微调训练模型最后一层（全连接分类层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "# 设置模型路径\n",
    "model_path = r'E:\\MV-Code-202018010103-Lucy\\Model\\full_model.pth'\n",
    "\n",
    "# 加载模型\n",
    "model = torch.load(model_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T05:38:39.319448100Z",
     "start_time": "2024-04-09T05:38:39.190561400Z"
    }
   },
   "id": "c029cdc19013b1fa"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConvertModel' object has no attribute 'dense'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[15], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model\u001B[38;5;241m.\u001B[39mdense \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdense\u001B[49m\u001B[38;5;241m.\u001B[39min_features, n_class)\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ConvertModel' object has no attribute 'dense'"
     ]
    }
   ],
   "source": [
    "model.fc = nn.Linear(model.fc.in_features, n_class)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T05:39:16.777584800Z",
     "start_time": "2024-04-09T05:39:16.660861800Z"
    }
   },
   "id": "5769d14989436c47"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "15772d27-7a9c-43e6-8750-5080e6085403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:25.637088800Z",
     "start_time": "2024-04-09T08:33:25.218553100Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "# 修改全连接层，使得全连接层的输出与当前数据集类别数对应\n",
    "# 新建的层默认 requires_grad=True\n",
    "model.fc = nn.Linear(model.fc.in_features, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7831dc08-e59e-4013-8390-b786fae0ed0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:27.328854700Z",
     "start_time": "2024-04-09T08:33:27.264825900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=512, out_features=2, bias=True)"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8456b4d8-1ca8-4725-9377-92e5224ffbf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:30.689658Z",
     "start_time": "2024-04-09T08:33:29.827689400Z"
    }
   },
   "outputs": [],
   "source": [
    "# 只微调训练最后一层全连接层的参数，其它层冻结\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf28f7-07f6-493a-b358-318b1a187a30",
   "metadata": {},
   "source": [
    "### 选择二：微调训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e00e1a34-19b7-47c7-ad7b-1a88d93ef709",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d831974-0425-4fe3-9eb0-1afc504b7bd2",
   "metadata": {},
   "source": [
    "### 选择三：随机初始化模型全部权重，从头训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "209747a8-38a7-481d-a0f4-fa9fda035d62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=False) # 只载入模型结构，不载入预训练权重参数\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e92213d-d6d9-435f-a4c0-4bcdbdf7c6b8",
   "metadata": {},
   "source": [
    "## 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5146eb0-f25e-400c-bbd6-e567f8aab8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:41.312549700Z",
     "start_time": "2024-04-09T08:33:40.993447600Z"
    }
   },
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# 交叉熵损失函数\n",
    "criterion = nn.CrossEntropyLoss() \n",
    "\n",
    "# 训练轮次 Epoch\n",
    "EPOCHS = 10\n",
    "\n",
    "# 学习率降低策略\n",
    "lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36146f7-afb5-416e-a7d2-938c0fd6ab6a",
   "metadata": {},
   "source": [
    "## 函数：在训练集上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a4fde230-042e-4e58-92eb-36d9febc8553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:44.524611500Z",
     "start_time": "2024-04-09T08:33:42.990673300Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c6511cc9-d9d8-4c67-9aed-e1c0ac14dbcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:46.770127200Z",
     "start_time": "2024-04-09T08:33:46.706407900Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    "    '''\n",
    "    运行一个 batch 的训练，返回当前 batch 的训练日志\n",
    "    '''\n",
    "    \n",
    "    # 获得一个 batch 的数据和标注\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images) # 输入模型，执行前向预测\n",
    "    loss = criterion(outputs, labels) # 计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "    \n",
    "    # 优化更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 获取当前 batch 的标签类别和预测类别\n",
    "    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # 计算分类评估指标\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return log_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db850cdd-41eb-454a-957d-9af9dad9165b",
   "metadata": {},
   "source": [
    "## 函数：在整个测试集上评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "709a01fc-05c8-4c4e-abca-6fcded8c838a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:48.317871800Z",
     "start_time": "2024-04-09T08:33:48.257308100Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    '''\n",
    "    在整个测试集上评估，返回分类评估指标日志\n",
    "    '''\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader: # 生成一个 batch 的数据和标注\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) # 输入模型，执行前向预测\n",
    "\n",
    "            # 获取整个测试集的标签类别和预测类别\n",
    "            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    \n",
    "    # 计算分类评估指标\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf43a5-2490-4772-9ed2-7e4e3025493f",
   "metadata": {},
   "source": [
    "## 训练开始之前，记录日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fee46b5e-4175-4de2-86d3-4f6159b99dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:33:53.540291500Z",
     "start_time": "2024-04-09T08:33:53.482475400Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3760c516-8301-4455-9eeb-c3eaa63ae249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:36:36.085589300Z",
     "start_time": "2024-04-09T08:36:19.452692800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练日志-训练集\n",
    "# 初始化空的 DataFrame\n",
    "\n",
    "df_train_log = pd.DataFrame()\n",
    "\n",
    "# 创建和更新 log_train 字典\n",
    "log_train = {'epoch': 0, 'batch': 0}\n",
    "images, labels = next(iter(train_loader))\n",
    "log_train.update(train_one_batch(images, labels))\n",
    "\n",
    "# 将 log_train 字典转换为 DataFrame\n",
    "log_train_df = pd.DataFrame([log_train])\n",
    "\n",
    "# 使用 pd.concat 合并 DataFrame\n",
    "df_train_log = pd.concat([df_train_log, log_train_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d11c0b7b-8482-4824-a46b-25c26ab804e5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:36:39.229587500Z",
     "start_time": "2024-04-09T08:36:39.141173300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   epoch  batch train_loss  train_accuracy\n0      0      0  0.7195293         0.53125",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>batch</th>\n      <th>train_loss</th>\n      <th>train_accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0.7195293</td>\n      <td>0.53125</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "af02f9ba-fa78-4164-8022-20205ff6e4d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:37:21.882102600Z",
     "start_time": "2024-04-09T08:36:54.443338200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练日志-测试集\n",
    "# 初始化空的 DataFrame\n",
    "df_test_log = pd.DataFrame()\n",
    "\n",
    "# 创建和更新 log_test 字典\n",
    "log_test = {'epoch': 0}\n",
    "log_test.update(evaluate_testset())\n",
    "\n",
    "# 将 log_test 字典转换为 DataFrame\n",
    "log_test_df = pd.DataFrame([log_test])\n",
    "\n",
    "# 使用 pd.concat 合并 DataFrame\n",
    "df_test_log = pd.concat([df_test_log, log_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5c8b30d7-3dd1-4b5e-98bf-8e07c1c334d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:37:23.955126Z",
     "start_time": "2024-04-09T08:37:23.888352800Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   epoch  test_loss  test_accuracy  test_precision  test_recall  test_f1-score\n0      0   0.746294       0.503084        0.508355     0.503084       0.410038",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>epoch</th>\n      <th>test_loss</th>\n      <th>test_accuracy</th>\n      <th>test_precision</th>\n      <th>test_recall</th>\n      <th>test_f1-score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.746294</td>\n      <td>0.503084</td>\n      <td>0.508355</td>\n      <td>0.503084</td>\n      <td>0.410038</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5bd92-b32c-4e75-850f-26e39ed75a8a",
   "metadata": {},
   "source": [
    "## 登录wandb\n",
    "\n",
    "1.安装 wandb：pip install wandb\n",
    "\n",
    "2.登录 wandb：在命令行中运行wandb login\n",
    "\n",
    "3.按提示复制粘贴API Key至命令行中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f0565-b004-45e7-963d-93fd55f1df34",
   "metadata": {},
   "source": [
    "## 创建wandb可视化项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eb211f1a-64fc-497a-abf5-5639618a3784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:42:49.934324900Z",
     "start_time": "2024-04-09T08:42:45.479869200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2320a54ee4244de0b5ec6ac20c3ce591"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.6"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>E:\\MV-Code-202018010103-Lucy\\wandb\\run-20240409_164245-nqzkatte</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='https://wandb.ai/luciferinc/SR-malaria/runs/nqzkatte' target=\"_blank\">0409164245</a></strong> to <a href='https://wandb.ai/luciferinc/SR-malaria' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='https://wandb.ai/luciferinc/SR-malaria' target=\"_blank\">https://wandb.ai/luciferinc/SR-malaria</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='https://wandb.ai/luciferinc/SR-malaria/runs/nqzkatte' target=\"_blank\">https://wandb.ai/luciferinc/SR-malaria/runs/nqzkatte</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/luciferinc/SR-malaria/runs/nqzkatte?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x266a8185670>"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='SR-malaria', name=time.strftime('%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fec36-70de-4a8a-a985-57148fd36815",
   "metadata": {},
   "source": [
    "## 运行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9000ce4e-7134-4c56-b95b-926cb5194b18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:46:02.646273900Z",
     "start_time": "2024-04-09T08:44:13.837959200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 689/689 [01:25<00:00,  8.03it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory checkpoint does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[43], line 42\u001B[0m\n\u001B[0;32m     40\u001B[0m         best_test_accuracy \u001B[38;5;241m=\u001B[39m log_test[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtest_accuracy\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m     41\u001B[0m         new_best_checkpoint_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcheckpoint/best-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_test_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m---> 42\u001B[0m         \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msave\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnew_best_checkpoint_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     43\u001B[0m         \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m保存新的最佳模型 checkpoint/best-\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mbest_test_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.3f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pth\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     45\u001B[0m \u001B[38;5;66;03m# 将日志保存为 CSV 文件\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:618\u001B[0m, in \u001B[0;36msave\u001B[1;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization, _disable_byteorder_record)\u001B[0m\n\u001B[0;32m    615\u001B[0m _check_save_filelike(f)\n\u001B[0;32m    617\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _use_new_zipfile_serialization:\n\u001B[1;32m--> 618\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[43m_open_zipfile_writer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m opened_zipfile:\n\u001B[0;32m    619\u001B[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol, _disable_byteorder_record)\n\u001B[0;32m    620\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:492\u001B[0m, in \u001B[0;36m_open_zipfile_writer\u001B[1;34m(name_or_buffer)\u001B[0m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    491\u001B[0m     container \u001B[38;5;241m=\u001B[39m _open_zipfile_writer_buffer\n\u001B[1;32m--> 492\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcontainer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname_or_buffer\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\serialization.py:463\u001B[0m, in \u001B[0;36m_open_zipfile_writer_file.__init__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m    461\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(torch\u001B[38;5;241m.\u001B[39m_C\u001B[38;5;241m.\u001B[39mPyTorchFileWriter(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfile_stream))\n\u001B[0;32m    462\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 463\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPyTorchFileWriter\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: Parent directory checkpoint does not exist."
     ]
    }
   ],
   "source": [
    "# 初始化 DataFrames\n",
    "df_train_log = pd.DataFrame()\n",
    "df_test_log = pd.DataFrame()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    \n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    for images, labels in tqdm(train_loader): # 获得一个 batch 的数据和标注\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "        \n",
    "        # 使用 pd.concat 而不是 append\n",
    "        log_train_df = pd.DataFrame([log_train])\n",
    "        df_train_log = pd.concat([df_train_log, log_train_df], ignore_index=True)\n",
    "\n",
    "        wandb.log(log_train)\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # 测试阶段\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    \n",
    "    # 使用 pd.concat 而不是 append\n",
    "    log_test_df = pd.DataFrame([log_test])\n",
    "    df_test_log = pd.concat([df_test_log, log_test_df], ignore_index=True)\n",
    "\n",
    "    wandb.log(log_test)\n",
    "    \n",
    "    # 保存最新的最佳模型文件\n",
    "    if log_test['test_accuracy'] > best_test_accuracy:\n",
    "        # 删除旧的最佳模型文件(如有)\n",
    "        old_best_checkpoint_path = f'checkpoint/best-{best_test_accuracy:.3f}.pth'\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "        # 保存新的最佳模型文件\n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = f'checkpoint/best-{best_test_accuracy:.3f}.pth'\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print(f'保存新的最佳模型 checkpoint/best-{best_test_accuracy:.3f}.pth')\n",
    "\n",
    "# 将日志保存为 CSV 文件\n",
    "df_train_log.to_csv('训练日志-训练集.csv', index=False)\n",
    "df_test_log.to_csv('训练日志-测试集.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdafc8-fca1-48f1-8fea-e864c3293d74",
   "metadata": {},
   "source": [
    "## 在测试集上评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d6512f03-53ff-428a-bff4-d151a2c57796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 载入最佳模型作为当前模型\n",
    "model = torch.load('checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2238ad86-508f-4a86-affd-fa6f8016e9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'epoch': 30, 'test_loss': 0.26338762, 'test_accuracy': 0.8766233766233766, 'test_precision': 0.8780937321959233, 'test_recall': 0.8752925121116021, 'test_f1-score': 0.8748063404834624}\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "print(evaluate_testset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e39fa3-29c0-489a-854e-b4df1c1bcf57",
   "metadata": {},
   "source": [
    "## 参考文档\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "https://www.bilibili.com/video/BV14J411X7Bb\n",
    "\n",
    "https://www.bilibili.com/video/BV1w4411u7ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa9ab1-70dc-4373-8f38-095553e9a953",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
