{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a36abc9-47b6-4e9a-8d2c-330e64012db2",
   "metadata": {},
   "source": [
    "# 迁移学习微调训练图像分类模型\n",
    "\n",
    "在自己的图像分类数据集上，使用ImageNet预训练图像分类模型初始化，改动分类层，迁移学习微调训练\n",
    "\n",
    "同济子豪兄：https://space.bilibili.com/1900783\n",
    "\n",
    "[代码运行云GPU环境](https://featurize.cn/?s=d7ce99f842414bfcaea5662a97581bd1)：GPU RTX 3060、CUDA v11.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9c174f-33c0-44fa-af53-14237d35b37d",
   "metadata": {},
   "source": [
    "## 导入工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b35d923-b9e9-4ea4-914a-5bf05b93a2b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:47.360392600Z",
     "start_time": "2024-04-09T05:22:47.276962600Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device cuda:0\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import Adam\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 忽略烦人的红色提示\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 获取计算硬件\n",
    "# 有 GPU 就用 GPU，没有就用 CPU\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print('device', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9499c1-0594-48b8-80f0-e7fdbc30dbe3",
   "metadata": {},
   "source": [
    "## 图像预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81f0ca03-de86-450d-a47e-6f0e7c19d97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:48.976589500Z",
     "start_time": "2024-04-09T05:22:48.880351600Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "# 训练集图像预处理：缩放裁剪、图像增强、转 Tensor、归一化\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                                     ])\n",
    "\n",
    "# 测试集图像预处理-RCTN：缩放、裁剪、转 Tensor、归一化\n",
    "test_transform = transforms.Compose([transforms.Resize(256),\n",
    "                                     transforms.CenterCrop(224),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize(\n",
    "                                         mean=[0.485, 0.456, 0.406], \n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "                                    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d059c79-5b67-49fe-9baa-1bcd363208dc",
   "metadata": {},
   "source": [
    "## 载入图像分类数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5fd21e05-6cd0-4e06-a0f1-a029a79ddf86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:51.346299400Z",
     "start_time": "2024-04-09T05:22:51.265111700Z"
    }
   },
   "outputs": [],
   "source": [
    "# 数据集文件夹路径\n",
    "dataset_dir = r'E:\\MV-Code\\Datasets\\archive\\SR-Base_datasets'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcf6544a-6af5-4b07-93df-d863157b9290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:53.481903200Z",
     "start_time": "2024-04-09T05:22:53.059895900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集路径 E:\\MV-Code\\Datasets\\archive\\SR-Base_datasets\\train\n",
      "测试集路径 E:\\MV-Code\\Datasets\\archive\\SR-Base_datasets\\val\n",
      "训练集图像数量 19290\n",
      "类别个数 2\n",
      "各类别名称 ['parasitized', 'uninfected']\n",
      "测试集图像数量 4134\n",
      "类别个数 2\n",
      "各类别名称 ['parasitized', 'uninfected']\n"
     ]
    }
   ],
   "source": [
    "train_path = os.path.join(dataset_dir, 'train')\n",
    "test_path = os.path.join(dataset_dir, 'val')\n",
    "print('训练集路径', train_path)\n",
    "print('测试集路径', test_path)\n",
    "\n",
    "from torchvision import datasets\n",
    "# 载入训练集\n",
    "train_dataset = datasets.ImageFolder(train_path, train_transform)\n",
    "# 载入测试集\n",
    "test_dataset = datasets.ImageFolder(test_path, test_transform)\n",
    "\n",
    "print('训练集图像数量', len(train_dataset))\n",
    "print('类别个数', len(train_dataset.classes))\n",
    "print('各类别名称', train_dataset.classes)\n",
    "print('测试集图像数量', len(test_dataset))\n",
    "print('类别个数', len(test_dataset.classes))\n",
    "print('各类别名称', test_dataset.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74e98be-4648-4d34-9e6c-273a55127b4d",
   "metadata": {},
   "source": [
    "## 类别和索引号 映射字典"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f737200-3afd-46f7-9c42-52c66829572e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:55.046270Z",
     "start_time": "2024-04-09T05:22:54.972217800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 各类别名称\n",
    "class_names = train_dataset.classes\n",
    "n_class = len(class_names)\n",
    "# 映射关系：类别 到 索引号\n",
    "train_dataset.class_to_idx\n",
    "# 映射关系：索引号 到 类别\n",
    "idx_to_labels = {y:x for x,y in train_dataset.class_to_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d0baa451-a3c8-456a-a1ad-ea814dc9958c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:57.441794500Z",
     "start_time": "2024-04-09T05:22:57.333160500Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{0: 'parasitized', 1: 'uninfected'}"
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_to_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eec89734-ec52-430c-a756-55faa2ce549b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:58.480370500Z",
     "start_time": "2024-04-09T05:22:58.379971200Z"
    }
   },
   "outputs": [],
   "source": [
    "# 保存为本地的 npy 文件\n",
    "np.save('idx_to_labels.npy', idx_to_labels)\n",
    "np.save('labels_to_idx.npy', train_dataset.class_to_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d3824-e6bb-4f50-9802-f073d9151311",
   "metadata": {},
   "source": [
    "## 定义数据加载器DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a787702d-61c6-41af-9cbd-19bc5d3baae7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:22:59.698181200Z",
     "start_time": "2024-04-09T05:22:59.628773300Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 训练集的数据加载器\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          num_workers=4\n",
    "                         )\n",
    "\n",
    "# 测试集的数据加载器\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=False,\n",
    "                         num_workers=4\n",
    "                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b52d04-a791-4feb-8b57-af98b253ebba",
   "metadata": {},
   "source": [
    "## 导入训练需使用的工具包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "684da643-5a88-4ba2-b49c-5dc98b35100e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:23:01.524414900Z",
     "start_time": "2024-04-09T05:23:01.446823100Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375b9c90-160f-451f-a46b-6e846424cc0a",
   "metadata": {},
   "source": [
    "## 选择迁移学习训练方式\n",
    "\n",
    "斯坦福CS231N【迁移学习】中文精讲：https://www.bilibili.com/video/BV1K7411W7So\n",
    "\n",
    "斯坦福CS231N【迁移学习】官方笔记：https://cs231n.github.io/transfer-learning\n",
    "\n",
    "如果你的数据集和MS COCO数据集的图像域**类似**（街景、动植物、生活用品），可以保留预训练模型权重，在自己的数据集上迁移学习微调分类输出层或所有层。站在巨人的肩膀上，复用预训练模型在MS COCO数据集上学习到的图像特征。（Transfer Learning, Fine Tuning）\n",
    "\n",
    "如果你的数据集和MS COCO数据集的图像域**不类似**（医疗影像、显微镜图像、工业检测、天文照片、动画、油画），可以随机初始化模型权重，在自己的数据集上重新训练所有层。（From Scratch）。或者冻结底层权重，只重新训练顶层，复用预训练模型在MS COCO数据集上学习到的底层图像特征。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d146006e-6bb2-4b34-8530-6c762398938e",
   "metadata": {},
   "source": [
    "### 选择一：只微调训练模型最后一层（全连接分类层）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15772d27-7a9c-43e6-8750-5080e6085403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:58:24.941430500Z",
     "start_time": "2024-04-08T15:58:24.716038400Z"
    }
   },
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "# 修改全连接层，使得全连接层的输出与当前数据集类别数对应\n",
    "# 新建的层默认 requires_grad=True\n",
    "model.fc = nn.Linear(model.fc.in_features, n_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7831dc08-e59e-4013-8390-b786fae0ed0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T15:58:26.364097400Z",
     "start_time": "2024-04-08T15:58:26.275876100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Linear(in_features=512, out_features=2, bias=True)"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8456b4d8-1ca8-4725-9377-92e5224ffbf0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-07T19:21:37.865239400Z",
     "start_time": "2024-04-07T19:21:37.572319300Z"
    }
   },
   "outputs": [],
   "source": [
    "# 只微调训练最后一层全连接层的参数，其它层冻结\n",
    "optimizer = optim.Adam(model.fc.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bf28f7-07f6-493a-b358-318b1a187a30",
   "metadata": {},
   "source": [
    "### 选择二：微调训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e1a34-19b7-47c7-ad7b-1a88d93ef709",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.433889800Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=True) # 载入预训练模型\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d831974-0425-4fe3-9eb0-1afc504b7bd2",
   "metadata": {},
   "source": [
    "### 选择三：随机初始化模型全部权重，从头训练所有层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209747a8-38a7-481d-a0f4-fa9fda035d62",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.436929400Z"
    }
   },
   "outputs": [],
   "source": [
    "# model = models.resnet18(pretrained=False) # 只载入模型结构，不载入预训练权重参数\n",
    "\n",
    "# model.fc = nn.Linear(model.fc.in_features, n_class)\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "# 设置模型路径\n",
    "model_path = r'E:\\MV-Code-202018010103-Lucy\\Model\\full_model.pth'\n",
    "\n",
    "# 加载模型\n",
    "model = torch.load(model_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T05:28:51.890515900Z",
     "start_time": "2024-04-09T05:28:51.782482500Z"
    }
   },
   "id": "c8a53c852ec95473"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ConvertModel' object has no attribute 'fc'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[71], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model\u001B[38;5;241m.\u001B[39mfc \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mLinear(\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc\u001B[49m\u001B[38;5;241m.\u001B[39min_features, n_class)\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001B[0m, in \u001B[0;36mModule.__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   1693\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[0;32m   1694\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[1;32m-> 1695\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m object has no attribute \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'ConvertModel' object has no attribute 'fc'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T05:28:45.591543900Z",
     "start_time": "2024-04-09T05:28:45.495947300Z"
    }
   },
   "id": "6fe70663fee6b598"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(self, channel, reduction=8):\n",
    "        super(SEBlock, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(channel, channel // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(channel // reduction, channel, bias=False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        y = self.avg_pool(x).view(b, c)\n",
    "        y = self.fc(y).view(b, c, 1, 1)\n",
    "        return x * y.expand_as(x)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T15:58:32.438125500Z",
     "start_time": "2024-04-08T15:58:32.357538700Z"
    }
   },
   "id": "158f8c2c76051d48"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "class CNN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN1, self).__init__()\n",
    "        \n",
    "        # Block 1\n",
    "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.bn1_1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        # Block 2\n",
    "        self.conv2_1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.bn2_1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        # Block 3\n",
    "        self.conv3_1 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn3_1 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # Block 4\n",
    "        self.conv4_1 = nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn4_1 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        # SE Block\n",
    "        self.se1 = SEBlock(channel=128)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Block 1\n",
    "        x = F.relu(self.bn1_1(self.conv1_1(x)))\n",
    "        print(f\"After block 1: {x.shape}\") # 添加这一行\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Block 2\n",
    "        x = F.relu(self.bn2_1(self.conv2_1(x)))\n",
    "        print(f\"After block 2: {x.shape}\") # 添加这一行\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # Block 3\n",
    "        x = F.relu(self.bn3_1(self.conv3_1(x)))\n",
    "        \n",
    "        # Block 4\n",
    "        x = F.relu(self.bn4_1(self.conv4_1(x)))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        \n",
    "        # SE Block\n",
    "        x = self.se1(x)\n",
    "        \n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T15:58:33.526561200Z",
     "start_time": "2024-04-08T15:58:33.430817200Z"
    }
   },
   "id": "14fc1d035ad6af9a"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN2, self).__init__()\n",
    "        \n",
    "        # Parallel Blocks, assuming Block1, Block2, and Block3 are similar\n",
    "        self.conv_blocks = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Conv2d(in_channels=3, out_channels=16, kernel_size=kernel_size, padding=kernel_size//2),\n",
    "                nn.BatchNorm2d(16),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                SEBlock(channel=16)\n",
    "            ) for kernel_size in [3, 5, 7]\n",
    "        ])\n",
    "        \n",
    "        # After concatenation\n",
    "        self.conv1_2 = nn.Conv2d(in_channels=48, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn1_2 = nn.BatchNorm2d(128)\n",
    "        self.pool1_2 = nn.MaxPool2d(kernel_size=4, stride=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Parallel Blocks\n",
    "        outputs = [block(x) for block in self.conv_blocks]\n",
    "        \n",
    "        # Concatenation\n",
    "        x = torch.cat(outputs, dim=1)\n",
    "        \n",
    "        # After concatenation\n",
    "        x = F.relu(self.bn1_2(self.conv1_2(x)))\n",
    "        x = self.pool1_2(x)\n",
    "        \n",
    "        return x\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T15:58:35.227755800Z",
     "start_time": "2024-04-08T15:58:35.137189300Z"
    }
   },
   "id": "44fffc5c4c29b0f0"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, input_size=(256, 256, 3)):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.cnn1 = CNN1()\n",
    "        self.cnn2 = CNN2()\n",
    "\n",
    "        # 创建一个临时输入,并调整通道数的位置\n",
    "        tmp_input = torch.randn(1, 3, *input_size[:2])\n",
    "        cnn1_output = self.cnn1(tmp_input)\n",
    "        cnn2_output = self.cnn2(tmp_input)\n",
    "\n",
    "        # 获取两个CNN网络输出的拉平后的维度\n",
    "        cnn1_output_size = cnn1_output.view(cnn1_output.size(0), -1).size(1)\n",
    "        cnn2_output_size = cnn2_output.view(cnn2_output.size(0), -1).size(1)\n",
    "        total_output_size = cnn1_output_size + cnn2_output_size\n",
    "\n",
    "        self.fc = nn.Linear(total_output_size, 1)  # 用于二分类\n",
    "\n",
    "    def forward(self, x):\n",
    "      if x.shape[1] != 3:\n",
    "          x = x.permute(0, 3, 1, 2)\n",
    "    \n",
    "      x1 = self.cnn1(x)\n",
    "      x2 = self.cnn2(x)\n",
    "    \n",
    "      print(f\"x1 shape: {x1.shape}\") \n",
    "      print(f\"x2 shape: {x2.shape}\")\n",
    "\n",
    "    # Flatten the features\n",
    "      x1 = x1.view(x1.size(0), -1)\n",
    "      x2 = x2.view(x2.size(0), -1)\n",
    "\n",
    "    # Concatenate features from both CNNs\n",
    "      x = torch.cat((x1, x2), dim=1)\n",
    "\n",
    "    # Pass through the final fully connected layer\n",
    "      x = self.fc(x)\n",
    "\n",
    "    # Adjust the output shape to match the target\n",
    "      x = x.squeeze(1)\n",
    "\n",
    "    # Convert output to Long data type\n",
    "      x = x.long()\n",
    "\n",
    "      return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-08T16:00:46.868944400Z",
     "start_time": "2024-04-08T16:00:46.779921500Z"
    }
   },
   "id": "7375b549909463a5"
  },
  {
   "cell_type": "markdown",
   "id": "6e92213d-d6d9-435f-a4c0-4bcdbdf7c6b8",
   "metadata": {},
   "source": [
    "## 训练配置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a5146eb0-f25e-400c-bbd6-e567f8aab8c9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T05:29:35.516203600Z",
     "start_time": "2024-04-09T05:29:35.407441900Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'input_size'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[74], line 5\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# 注意，这里使用的损失函数是nn.BCEWithLogitsLoss\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m# 它是sigmoid激活和二进制交叉熵损失的组合，适用于二分类任务\u001B[39;00m\n\u001B[0;32m      3\u001B[0m criterion \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mBCEWithLogitsLoss()\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minput_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m256\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m      6\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m Adam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[0;32m      7\u001B[0m lr_scheduler \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mStepLR(optimizer, step_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m, gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.5\u001B[39m)\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m forward_call(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: forward() got an unexpected keyword argument 'input_size'"
     ]
    }
   ],
   "source": [
    "# 注意，这里使用的损失函数是nn.BCEWithLogitsLoss\n",
    "# 它是sigmoid激活和二进制交叉熵损失的组合，适用于二分类任务\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model = model(input_size=(256,256,3)).to(device)\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "\n",
    "# 训练轮次 Epoch\n",
    "EPOCHS = 30\n",
    "\n",
    "# ...这里添加训练循环代码...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1908337407.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;36m  Cell \u001B[1;32mIn[51], line 2\u001B[1;36m\u001B[0m\n\u001B[1;33m    model = CombinedModel(input_size=(,256,256,3)).to(device)\u001B[0m\n\u001B[1;37m                                      ^\u001B[0m\n\u001B[1;31mSyntaxError\u001B[0m\u001B[1;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T04:12:26.512272200Z",
     "start_time": "2024-04-09T04:12:26.445262500Z"
    }
   },
   "id": "7dd51f79a98e8b7a"
  },
  {
   "cell_type": "markdown",
   "id": "a36146f7-afb5-416e-a7d2-938c0fd6ab6a",
   "metadata": {},
   "source": [
    "## 函数：在训练集上训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a4fde230-042e-4e58-92eb-36d9febc8553",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:14:52.566060100Z",
     "start_time": "2024-04-08T16:14:52.476982Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c6511cc9-d9d8-4c67-9aed-e1c0ac14dbcb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:18:45.238763600Z",
     "start_time": "2024-04-08T16:18:45.156200600Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_one_batch(images, labels):\n",
    "    '''\n",
    "    运行一个 batch 的训练，返回当前 batch 的训练日志\n",
    "    '''\n",
    "    \n",
    "    # 获得一个 batch 的数据和标注\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    outputs = model(images) # 输入模型，执行前向预测\n",
    "    outputs = outputs.squeeze(-1)  # 将输出形状调整为(batch_size,)\n",
    "    outputs = outputs.float()  # 确保输出是浮点类型\n",
    "    labels = labels.float()  # 将标签转换为浮点型\n",
    "    loss = criterion(outputs, labels)  # 计算当前 batch 中的损失函数值\n",
    "\n",
    "    \n",
    "    # 优化更新权重\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # 获取当前 batch 的标签类别和预测类别\n",
    "    _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "    preds = preds.cpu().numpy()\n",
    "    loss = loss.detach().cpu().numpy()\n",
    "    outputs = outputs.detach().cpu().numpy()\n",
    "    labels = labels.detach().cpu().numpy()\n",
    "    \n",
    "    log_train = {}\n",
    "    log_train['epoch'] = epoch\n",
    "    log_train['batch'] = batch_idx\n",
    "    # 计算分类评估指标\n",
    "    log_train['train_loss'] = loss\n",
    "    log_train['train_accuracy'] = accuracy_score(labels, preds)\n",
    "    # log_train['train_precision'] = precision_score(labels, preds, average='macro')\n",
    "    # log_train['train_recall'] = recall_score(labels, preds, average='macro')\n",
    "    # log_train['train_f1-score'] = f1_score(labels, preds, average='macro')\n",
    "    \n",
    "    return log_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db850cdd-41eb-454a-957d-9af9dad9165b",
   "metadata": {},
   "source": [
    "## 函数：在整个测试集上评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "709a01fc-05c8-4c4e-abca-6fcded8c838a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:18:46.852168100Z",
     "start_time": "2024-04-08T16:18:46.768198400Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_testset():\n",
    "    '''\n",
    "    在整个测试集上评估，返回分类评估指标日志\n",
    "    '''\n",
    "\n",
    "    loss_list = []\n",
    "    labels_list = []\n",
    "    preds_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader: # 生成一个 batch 的数据和标注\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            outputs = model(images) # 输入模型，执行前向预测\n",
    "\n",
    "            # 获取整个测试集的标签类别和预测类别\n",
    "            _, preds = torch.max(outputs, 1) # 获得当前 batch 所有图像的预测类别\n",
    "            preds = preds.cpu().numpy()\n",
    "            loss = criterion(outputs, labels) # 由 logit，计算当前 batch 中，每个样本的平均交叉熵损失函数值\n",
    "            loss = loss.detach().cpu().numpy()\n",
    "            outputs = outputs.detach().cpu().numpy()\n",
    "            labels = labels.detach().cpu().numpy()\n",
    "\n",
    "            loss_list.append(loss)\n",
    "            labels_list.extend(labels)\n",
    "            preds_list.extend(preds)\n",
    "        \n",
    "    log_test = {}\n",
    "    log_test['epoch'] = epoch\n",
    "    \n",
    "    # 计算分类评估指标\n",
    "    log_test['test_loss'] = np.mean(loss_list)\n",
    "    log_test['test_accuracy'] = accuracy_score(labels_list, preds_list)\n",
    "    log_test['test_precision'] = precision_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_recall'] = recall_score(labels_list, preds_list, average='macro')\n",
    "    log_test['test_f1-score'] = f1_score(labels_list, preds_list, average='macro')\n",
    "    \n",
    "    return log_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdf43a5-2490-4772-9ed2-7e4e3025493f",
   "metadata": {},
   "source": [
    "## 训练开始之前，记录日志"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fee46b5e-4175-4de2-86d3-4f6159b99dbd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:18:48.503770700Z",
     "start_time": "2024-04-08T16:18:48.427711800Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 0\n",
    "batch_idx = 0\n",
    "best_test_accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3760c516-8301-4455-9eeb-c3eaa63ae249",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-08T16:19:05.210362Z",
     "start_time": "2024-04-08T16:18:49.251471200Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After block 1: torch.Size([32, 32, 256, 256])\n",
      "After block 2: torch.Size([32, 64, 128, 128])\n",
      "x1 shape: torch.Size([32, 128, 32, 32])\n",
      "x2 shape: torch.Size([32, 128, 32, 32])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[50], line 9\u001B[0m\n\u001B[0;32m      7\u001B[0m log_train \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mepoch\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mbatch\u001B[39m\u001B[38;5;124m'\u001B[39m: \u001B[38;5;241m0\u001B[39m}\n\u001B[0;32m      8\u001B[0m images, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(train_loader))\n\u001B[1;32m----> 9\u001B[0m log_train\u001B[38;5;241m.\u001B[39mupdate(\u001B[43mtrain_one_batch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# 将 log_train 字典转换为 DataFrame\u001B[39;00m\n\u001B[0;32m     12\u001B[0m log_train_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame([log_train])\n",
      "Cell \u001B[1;32mIn[47], line 19\u001B[0m, in \u001B[0;36mtrain_one_batch\u001B[1;34m(images, labels)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# 优化更新权重\u001B[39;00m\n\u001B[0;32m     18\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 19\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     20\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m# 获取当前 batch 的标签类别和预测类别\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\_tensor.py:492\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    482\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    483\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    484\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    485\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    490\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    491\u001B[0m     )\n\u001B[1;32m--> 492\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    493\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    494\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\torch\\autograd\\__init__.py:251\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    246\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    248\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    249\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    250\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 251\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    252\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    253\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    254\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    255\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    257\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    258\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    259\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# 训练日志-训练集\n",
    "# 初始化空的 DataFrame\n",
    "\n",
    "df_train_log = pd.DataFrame()\n",
    "\n",
    "# 创建和更新 log_train 字典\n",
    "log_train = {'epoch': 0, 'batch': 0}\n",
    "images, labels = next(iter(train_loader))\n",
    "log_train.update(train_one_batch(images, labels))\n",
    "\n",
    "# 将 log_train 字典转换为 DataFrame\n",
    "log_train_df = pd.DataFrame([log_train])\n",
    "\n",
    "# 使用 pd.concat 合并 DataFrame\n",
    "df_train_log = pd.concat([df_train_log, log_train_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c0b7b-8482-4824-a46b-25c26ab804e5",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.456800900Z"
    }
   },
   "outputs": [],
   "source": [
    "df_train_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af02f9ba-fa78-4164-8022-20205ff6e4d3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.458827900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 训练日志-测试集\n",
    "# 初始化空的 DataFrame\n",
    "df_test_log = pd.DataFrame()\n",
    "\n",
    "# 创建和更新 log_test 字典\n",
    "log_test = {'epoch': 0}\n",
    "log_test.update(evaluate_testset())\n",
    "\n",
    "# 将 log_test 字典转换为 DataFrame\n",
    "log_test_df = pd.DataFrame([log_test])\n",
    "\n",
    "# 使用 pd.concat 合并 DataFrame\n",
    "df_test_log = pd.concat([df_test_log, log_test_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b30d7-3dd1-4b5e-98bf-8e07c1c334d1",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.460871700Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test_log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e5bd92-b32c-4e75-850f-26e39ed75a8a",
   "metadata": {},
   "source": [
    "## 登录wandb\n",
    "\n",
    "1.安装 wandb：pip install wandb\n",
    "\n",
    "2.登录 wandb：在命令行中运行wandb login\n",
    "\n",
    "3.按提示复制粘贴API Key至命令行中"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f0565-b004-45e7-963d-93fd55f1df34",
   "metadata": {},
   "source": [
    "## 创建wandb可视化项目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eb211f1a-64fc-497a-abf5-5639618a3784",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-09T08:40:51.266198400Z",
     "start_time": "2024-04-09T08:40:42.587272600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: yungleanalwaysright (luciferinc). Use `wandb login --relogin` to force relogin\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 1177, in init\n",
      "    wi.setup(kwargs)\n",
      "  File \"D:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 331, in setup\n",
      "    self._log_setup(settings)\n",
      "  File \"D:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py\", line 488, in _log_setup\n",
      "    filesystem.mkdir_exists_ok(os.path.dirname(settings.log_user))\n",
      "  File \"D:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\lib\\filesystem.py\", line 30, in mkdir_exists_ok\n",
      "    os.makedirs(dir_name, exist_ok=True)\n",
      "  File \"D:\\Software\\anaconda\\envs\\Pytorch\\lib\\os.py\", line 215, in makedirs\n",
      "    makedirs(head, exist_ok=exist_ok)\n",
      "  File \"D:\\Software\\anaconda\\envs\\Pytorch\\lib\\os.py\", line 225, in makedirs\n",
      "    mkdir(name, mode)\n",
      "OSError: [WinError 112] There is not enough space on the disk: 'E:\\\\MV-Code-202018010103-Lucy\\\\main\\\\Train_Custom_Dataset\\\\图像分类\\\\3-【Pytorch】迁移学习训练自己的图像分类模型\\\\wandb\\\\run-20240409_164049-jrfvqm66'\n"
     ]
    },
    {
     "ename": "Error",
     "evalue": "An unexpected error occurred",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mOSError\u001B[0m                                   Traceback (most recent call last)",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1177\u001B[0m, in \u001B[0;36minit\u001B[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001B[0m\n\u001B[0;32m   1176\u001B[0m wi \u001B[38;5;241m=\u001B[39m _WandbInit()\n\u001B[1;32m-> 1177\u001B[0m \u001B[43mwi\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msetup\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1178\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m wi\u001B[38;5;241m.\u001B[39msettings\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:331\u001B[0m, in \u001B[0;36m_WandbInit.setup\u001B[1;34m(self, kwargs)\u001B[0m\n\u001B[0;32m    330\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m settings\u001B[38;5;241m.\u001B[39m_noop:\n\u001B[1;32m--> 331\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_log_setup\u001B[49m\u001B[43m(\u001B[49m\u001B[43msettings\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    333\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m settings\u001B[38;5;241m.\u001B[39m_jupyter:\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:488\u001B[0m, in \u001B[0;36m_WandbInit._log_setup\u001B[1;34m(self, settings)\u001B[0m\n\u001B[0;32m    487\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Set up logging from settings.\"\"\"\u001B[39;00m\n\u001B[1;32m--> 488\u001B[0m \u001B[43mfilesystem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmkdir_exists_ok\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdirname\u001B[49m\u001B[43m(\u001B[49m\u001B[43msettings\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlog_user\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    489\u001B[0m filesystem\u001B[38;5;241m.\u001B[39mmkdir_exists_ok(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mdirname(settings\u001B[38;5;241m.\u001B[39mlog_internal))\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\lib\\filesystem.py:30\u001B[0m, in \u001B[0;36mmkdir_exists_ok\u001B[1;34m(dir_name)\u001B[0m\n\u001B[0;32m     29\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 30\u001B[0m     \u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdir_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\os.py:215\u001B[0m, in \u001B[0;36mmakedirs\u001B[1;34m(name, mode, exist_ok)\u001B[0m\n\u001B[0;32m    214\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 215\u001B[0m     \u001B[43mmakedirs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhead\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexist_ok\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mexist_ok\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mFileExistsError\u001B[39;00m:\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;66;03m# Defeats race condition when another thread created the path\u001B[39;00m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\os.py:225\u001B[0m, in \u001B[0;36mmakedirs\u001B[1;34m(name, mode, exist_ok)\u001B[0m\n\u001B[0;32m    224\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 225\u001B[0m     \u001B[43mmkdir\u001B[49m\u001B[43m(\u001B[49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    226\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m:\n\u001B[0;32m    227\u001B[0m     \u001B[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001B[39;00m\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001B[39;00m\n",
      "\u001B[1;31mOSError\u001B[0m: [WinError 112] There is not enough space on the disk: 'E:\\\\MV-Code-202018010103-Lucy\\\\main\\\\Train_Custom_Dataset\\\\图像分类\\\\3-【Pytorch】迁移学习训练自己的图像分类模型\\\\wandb\\\\run-20240409_164049-jrfvqm66'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[1;31mError\u001B[0m                                     Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[75], line 3\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwandb\u001B[39;00m\n\u001B[1;32m----> 3\u001B[0m \u001B[43mwandb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mproject\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mfruit30\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstrftime\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mm\u001B[39;49m\u001B[38;5;132;43;01m%d\u001B[39;49;00m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mH\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mM\u001B[39;49m\u001B[38;5;124;43m%\u001B[39;49m\u001B[38;5;124;43mS\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Software\\anaconda\\envs\\Pytorch\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:1219\u001B[0m, in \u001B[0;36minit\u001B[1;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, fork_from, settings)\u001B[0m\n\u001B[0;32m   1217\u001B[0m             wandb\u001B[38;5;241m.\u001B[39mtermerror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAbnormal program exit\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m   1218\u001B[0m             os\u001B[38;5;241m.\u001B[39m_exit(\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m-> 1219\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m Error(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAn unexpected error occurred\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merror_seen\u001B[39;00m\n\u001B[0;32m   1220\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m run\n",
      "\u001B[1;31mError\u001B[0m: An unexpected error occurred"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.init(project='fruit30', name=time.strftime('%m%d%H%M%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733fec36-70de-4a8a-a985-57148fd36815",
   "metadata": {},
   "source": [
    "## 运行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000ce4e-7134-4c56-b95b-926cb5194b18",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.463908800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 初始化 DataFrames\n",
    "df_train_log = pd.DataFrame()\n",
    "df_test_log = pd.DataFrame()\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    print(f'Epoch {epoch}/{EPOCHS}')\n",
    "    \n",
    "    # 训练阶段\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    for images, labels in tqdm(train_loader): # 获得一个 batch 的数据和标注\n",
    "        batch_idx += 1\n",
    "        log_train = train_one_batch(images, labels)\n",
    "        \n",
    "        # 使用 pd.concat 而不是 append\n",
    "        log_train_df = pd.DataFrame([log_train])\n",
    "        df_train_log = pd.concat([df_train_log, log_train_df], ignore_index=True)\n",
    "\n",
    "        wandb.log(log_train)\n",
    "        \n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # 测试阶段\n",
    "    model.eval()\n",
    "    log_test = evaluate_testset()\n",
    "    \n",
    "    # 使用 pd.concat 而不是 append\n",
    "    log_test_df = pd.DataFrame([log_test])\n",
    "    df_test_log = pd.concat([df_test_log, log_test_df], ignore_index=True)\n",
    "\n",
    "    wandb.log(log_test)\n",
    "    \n",
    "    # 保存最新的最佳模型文件\n",
    "    if log_test['test_accuracy'] > best_test_accuracy:\n",
    "        # 删除旧的最佳模型文件(如有)\n",
    "        old_best_checkpoint_path = f'checkpoint/best-{best_test_accuracy:.3f}.pth'\n",
    "        if os.path.exists(old_best_checkpoint_path):\n",
    "            os.remove(old_best_checkpoint_path)\n",
    "        # 保存新的最佳模型文件\n",
    "        best_test_accuracy = log_test['test_accuracy']\n",
    "        new_best_checkpoint_path = f'checkpoint/best-{best_test_accuracy:.3f}.pth'\n",
    "        torch.save(model, new_best_checkpoint_path)\n",
    "        print(f'保存新的最佳模型 checkpoint/best-{best_test_accuracy:.3f}.pth')\n",
    "\n",
    "# 将日志保存为 CSV 文件\n",
    "df_train_log.to_csv('训练日志-训练集.csv', index=False)\n",
    "df_test_log.to_csv('训练日志-测试集.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56bdafc8-fca1-48f1-8fea-e864c3293d74",
   "metadata": {},
   "source": [
    "## 在测试集上评价"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6512f03-53ff-428a-bff4-d151a2c57796",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.465936900Z"
    }
   },
   "outputs": [],
   "source": [
    "# 载入最佳模型作为当前模型\n",
    "model = torch.load('checkpoint/best-{:.3f}.pth'.format(best_test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2238ad86-508f-4a86-affd-fa6f8016e9bb",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.467958100Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "print(evaluate_testset())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e39fa3-29c0-489a-854e-b4df1c1bcf57",
   "metadata": {},
   "source": [
    "## 参考文档\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
    "\n",
    "https://www.bilibili.com/video/BV14J411X7Bb\n",
    "\n",
    "https://www.bilibili.com/video/BV1w4411u7ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa9ab1-70dc-4373-8f38-095553e9a953",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-04-07T19:20:41.468968700Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
